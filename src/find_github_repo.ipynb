{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# find_github_repo\n",
    "\n",
    "## Goals\n",
    "\n",
    "- To extract the names of github repositories from Pubmed abstracts that mention github.\n",
    "- To use the github api to get author and contribution data about those repositories\n",
    "- To create a dataset linking the two\n",
    "\n",
    "The bit that reads in xml files and extracts article information to a data frame is from Kevin's xml_parsing script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, set working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['github_pubs.xml', 'README.md']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"../data/\")\n",
    "os.listdir(\"./\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, import libraries needed for xml parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Article class definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Article(object):\n",
    "    \"\"\"Container for publication info\"\"\"\n",
    "    def __init__(self, pmid, pubdate, journal, title, abstract, authors):\n",
    "        self.pmid = pmid\n",
    "        self.pubdate = pubdate\n",
    "        self.journal = journal\n",
    "        self.title = title\n",
    "        self.abstract = abstract\n",
    "        self.authors = authors\n",
    "    def __repr__(self):\n",
    "        return \"<Article PMID: {}>\".format(self.pmid)\n",
    "\n",
    "    def get_authors(self):\n",
    "        for author in self.authors:\n",
    "            yield author[\"Last\"], author[\"First\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Article generator function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_pubmed_xml(xml_file):\n",
    "    xml_handle = ET.parse(xml_file)\n",
    "    root = xml_handle.getroot()\n",
    "\n",
    "    for Citation in root.iter(\"MedlineCitation\"):\n",
    "        pmid = Citation[0].text\n",
    "        pubdate = datetime.date(\n",
    "            int(Citation[1][0].text),  # year\n",
    "            int(Citation[1][1].text),  # month\n",
    "            int(Citation[1][2].text)  # day\n",
    "            )\n",
    "        \n",
    "        Journal = next(Citation.iter(\"Journal\"))\n",
    "\n",
    "        journal_title = Journal.find(\"ISOAbbreviation\").text\n",
    "        article_title = next(Citation.iter(\"ArticleTitle\")).text\n",
    "        \n",
    "        abstract = next(Citation.iter(\"AbstractText\")).text\n",
    "        try:\n",
    "            authors = [{\n",
    "                \"Last\": Author.find(\"LastName\").text,\n",
    "                \"First\": Author.find(\"ForeName\").text\n",
    "                   } for Author in Citation.iter(\"Author\")]\n",
    "        except:\n",
    "           continue\n",
    "        \n",
    "        yield Article(pmid, pubdate, journal_title, article_title, abstract, authors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make data frame (this differs a bit from Kevin's code by including abstract and url field) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abstract</th>\n",
       "      <th>Authors</th>\n",
       "      <th>Date</th>\n",
       "      <th>Github</th>\n",
       "      <th>Journal</th>\n",
       "      <th>Url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>26357045</th>\n",
       "      <td>Stability and sensitivity analyses of biologic...</td>\n",
       "      <td>[(Shiraishi, Fumihide), (Yoshida, Erika), (Voi...</td>\n",
       "      <td>2015-09-11</td>\n",
       "      <td></td>\n",
       "      <td>IEEE/ACM Trans Comput Biol Bioinform</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25601296</th>\n",
       "      <td>Most electronic data capture (EDC) and electro...</td>\n",
       "      <td>[(Dixit, Abhishek), (Dobson, Richard J B)]</td>\n",
       "      <td>2015-01-20</td>\n",
       "      <td></td>\n",
       "      <td>JMIR Med Inform</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25558360</th>\n",
       "      <td>Remotely sensed data - available at medium to ...</td>\n",
       "      <td>[(Tuck, Sean L), (Phillips, Helen Rp), (Hintze...</td>\n",
       "      <td>2015-01-05</td>\n",
       "      <td></td>\n",
       "      <td>Ecol Evol</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25553811</th>\n",
       "      <td>Whole-genome bisulfite sequencing (WGBS) is an...</td>\n",
       "      <td>[(Chen, Junfang), (Lutsik, Pavlo), (Akulenko, ...</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td></td>\n",
       "      <td>J Bioinform Comput Biol</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25549775</th>\n",
       "      <td>A number of computational approaches have been...</td>\n",
       "      <td>[(Manini, Simone), (Antiga, Luca), (Botti, Lor...</td>\n",
       "      <td>2015-06-09</td>\n",
       "      <td></td>\n",
       "      <td>Ann Biomed Eng</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Abstract  \\\n",
       "26357045  Stability and sensitivity analyses of biologic...   \n",
       "25601296  Most electronic data capture (EDC) and electro...   \n",
       "25558360  Remotely sensed data - available at medium to ...   \n",
       "25553811  Whole-genome bisulfite sequencing (WGBS) is an...   \n",
       "25549775  A number of computational approaches have been...   \n",
       "\n",
       "                                                    Authors        Date  \\\n",
       "26357045  [(Shiraishi, Fumihide), (Yoshida, Erika), (Voi...  2015-09-11   \n",
       "25601296         [(Dixit, Abhishek), (Dobson, Richard J B)]  2015-01-20   \n",
       "25558360  [(Tuck, Sean L), (Phillips, Helen Rp), (Hintze...  2015-01-05   \n",
       "25553811  [(Chen, Junfang), (Lutsik, Pavlo), (Akulenko, ...  2015-01-02   \n",
       "25549775  [(Manini, Simone), (Antiga, Luca), (Botti, Lor...  2015-06-09   \n",
       "\n",
       "         Github                               Journal Url  \n",
       "26357045         IEEE/ACM Trans Comput Biol Bioinform      \n",
       "25601296                              JMIR Med Inform      \n",
       "25558360                                    Ecol Evol      \n",
       "25553811                      J Bioinform Comput Biol      \n",
       "25549775                               Ann Biomed Eng      "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame()\n",
    "col_names = [\"Date\", \"Journal\", \"Authors\",\"Abstract\",\"Url\",\"Github\"]\n",
    "\n",
    "for article in parse_pubmed_xml('github_pubs.xml'):\n",
    "    row = pd.Series([article.pubdate, article.journal, [(author[0], author[1]) for author in article.get_authors()],\n",
    "                     article.abstract, '', ''],name=article.pmid, index=col_names)\n",
    "    df = df.append(row)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Check the content of the first abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Stability and sensitivity analyses of biological systems require the ad hocwriting of computer code, which is highly dependent on the particular model and burdensome for large systems. We propose a very accurate strategy to overcome this challenge. Its core concept is the conversion of the model into the format of biochemical systems theory (BST), which greatly facilitates the computation of sensitivities. First, the steady state of interest is determined by integrating the model equations toward the steady state and then using a Newton-Raphson method to fine-tune the result. The second step of conversion into the BST format requires several instances of numerical differentiation. The accuracy of this task is ensured by the use of a complex-variable Taylor scheme for all differentiation steps. The proposed strategy is implemented in a new software program, COSMOS, which automates the stability and sensitivity analysis of essentially arbitrary ODE models in a quick, yet highly accurate manner. The methods underlying the process are theoretically analyzed and illustrated with four representative examples: a simple metabolic reaction model; a model of aspartate-derived amino acid biosynthesis; a TCA-cycle model; and a modified TCA-cycle model. COSMOS has been deposited to https://github.com/BioprocessdesignLab/COSMOS.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iat[0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use regexp to extract github url from abstract (adapted from  http://stackoverflow.com/questions/839994/extracting-a-url-in-python) - This is overkill, but does the job. We need re to use regular expressoions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "URL_REGEX = r\"\"\"(?i)\\b((?:https?:(?:/{1,3}|[a-z0-9%])|[a-z0-9.\\-]+[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)/)(?:[^\\s()<>{}\\[\\]]+|\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\))+(?:\\([^\\s()]*?\\([^\\s()]+\\)[^\\s()]*?\\)|\\([^\\s]+?\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’])|(?:(?<!@)[a-z0-9]+(?:[.\\-][a-z0-9]+)*[.](?:com|net|org|edu|gov|mil|aero|asia|biz|cat|coop|info|int|jobs|mobi|museum|name|post|pro|tel|travel|xxx|ac|ad|ae|af|ag|ai|al|am|an|ao|aq|ar|as|at|au|aw|ax|az|ba|bb|bd|be|bf|bg|bh|bi|bj|bm|bn|bo|br|bs|bt|bv|bw|by|bz|ca|cc|cd|cf|cg|ch|ci|ck|cl|cm|cn|co|cr|cs|cu|cv|cx|cy|cz|dd|de|dj|dk|dm|do|dz|ec|ee|eg|eh|er|es|et|eu|fi|fj|fk|fm|fo|fr|ga|gb|gd|ge|gf|gg|gh|gi|gl|gm|gn|gp|gq|gr|gs|gt|gu|gw|gy|hk|hm|hn|hr|ht|hu|id|ie|il|im|in|io|iq|ir|is|it|je|jm|jo|jp|ke|kg|kh|ki|km|kn|kp|kr|kw|ky|kz|la|lb|lc|li|lk|lr|ls|lt|lu|lv|ly|ma|mc|md|me|mg|mh|mk|ml|mm|mn|mo|mp|mq|mr|ms|mt|mu|mv|mw|mx|my|mz|na|nc|ne|nf|ng|ni|nl|no|np|nr|nu|nz|om|pa|pe|pf|pg|ph|pk|pl|pm|pn|pr|ps|pt|pw|py|qa|re|ro|rs|ru|rw|sa|sb|sc|sd|se|sg|sh|si|sj|Ja|sk|sl|sm|sn|so|sr|ss|st|su|sv|sx|sy|sz|tc|td|tf|tg|th|tj|tk|tl|tm|tn|to|tp|tr|tt|tv|tw|tz|ua|ug|uk|us|uy|uz|va|vc|ve|vg|vi|vn|vu|wf|ws|ye|yt|yu|za|zm|zw)\\b/?(?!@)))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_github_regexp = r'(?i)\\b((?:https?://[.]*github[.]*))'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loop through all rows and extract github url from abstract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from urlparse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "except_no = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Extracting urls containing the string github to create project url entry works well; need to work on parsing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-134-03f263e0cc5d>, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-134-03f263e0cc5d>\"\u001b[1;36m, line \u001b[1;32m20\u001b[0m\n\u001b[1;33m    else\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,(len(df.index)-1)):             \n",
    "    abstract = df.iat[i,0]\n",
    "    github_project = ''\n",
    "    try:\n",
    "        project_url_list = re.findall(URL_REGEX, abstract)\n",
    "        \n",
    "        index = next(j for j, string in enumerate(project_url_list) if \"github\" in string)\n",
    "        project_url = project_url_list[index]\n",
    "                    \n",
    "        df.iat[i,5] = project_url\n",
    "\n",
    "        if project_url.startswith('https://github.com') or project_url.startswith('http://github.com'):\n",
    "            github_project = urlparse(project_url).path[1:]\n",
    "            df.iat[i,3] = github_project\n",
    "        \n",
    "        elif project_url.startswith('github.com'):\n",
    "            github_project = project_url[11:]\n",
    "            df.iat[i,3] = github_project\n",
    "            \n",
    "        else\n",
    "            df.iat[i,3] = ''\n",
    "        \n",
    "    except:\n",
    "        except_no = except_no + 1 \n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Check that this worked for most entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print except_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.head(200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "github_regexp = r\"\"\"(?i)(https?://[.]*github[.]*)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = str(df.iat[0,5])\n",
    "print test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test2 = str(df.iat[4,5])\n",
    "print test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urlparse(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "urlparse(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gurl = urlparse(\"https://github.com/BioprosessdesignLab/COSMOS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(gurl.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.find(\"https://github.com/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "access github api using pygithub\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from github import Github\n",
    "\n",
    "g = Github()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "whisper = g.get_repo(\"graphite-project/whisper\")\n",
    "print whisper.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cosmos = g.get_repo(\"BioprocessdesignLab/COSMOS\")\n",
    "print cosmos.description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "archtk = g.get_repo(\"archtk\")\n",
    "print archtk.description"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
